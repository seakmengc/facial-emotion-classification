{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "kLo5LnLudB6L"
      },
      "outputs": [],
      "source": [
        "# import pandas as pd\n",
        "\n",
        "# trains = []\n",
        "# tests = []\n",
        "# with open('dataset/label.txt', 'r') as label_f:\n",
        "#   line = label_f.readline()\n",
        "#   while line:\n",
        "#     splitted = line.split(' ')\n",
        "#     names = splitted[0].split('.')\n",
        "#     if line.startswith('train_'):\n",
        "#       trains.append([str(names[0] + '_aligned.' + names[1]), int(splitted[1][0]) - 1])\n",
        "#     else:\n",
        "#       tests.append([str(names[0] + '_aligned.' + names[1]), int(splitted[1][0]) - 1])\n",
        "\n",
        "#     line = label_f.readline()\n",
        "\n",
        "# pd.DataFrame(data=trains, columns=['path', 'label']).to_csv('dataset/train.csv', index=False)\n",
        "# pd.DataFrame(data=tests, columns=['path', 'label']).to_csv('dataset/test.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "_Rf0L7Tc3CCs"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\cseak\\anaconda3\\lib\\site-packages\\torchvision\\io\\image.py:11: UserWarning: Failed to load image Python extension: Could not find module 'C:\\Users\\cseak\\anaconda3\\Lib\\site-packages\\torchvision\\image.pyd' (or one of its dependencies). Try using the full path with constructor syntax.\n",
            "  warn(f\"Failed to load image Python extension: {e}\")\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import train_test_split\n",
        "from collections import Counter\n",
        "import time\n",
        "import torch\n",
        "import os\n",
        "import shutil\n",
        "import copy\n",
        "\n",
        "import PIL\n",
        "from PIL import Image\n",
        "\n",
        "import pathlib\n",
        "\n",
        "import os\n",
        "import time\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "import pytorch_lightning as pl\n",
        "import torchvision\n",
        "from torch import nn\n",
        "from torchmetrics.functional import accuracy\n",
        "from torchsummary import summary\n",
        "from torch.utils.data import Subset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "8RCAlKPwEeZz"
      },
      "outputs": [],
      "source": [
        "def log_to_file(self, id: str, train_acc, train_loss, val_acc, val_loss):\n",
        "        append = f\"{id},{train_acc},{train_loss},{val_acc},{val_loss}\\n\"\n",
        "        full_path = os.path.abspath(os.getcwd()) + self.log_path\n",
        "        \n",
        "        with open(full_path, \"a\") as f:\n",
        "            if os.path.getsize(full_path) <= 0:\n",
        "                f.write(\"id,train_acc,train_loss,val_acc,val_loss\\n\")\n",
        "                \n",
        "            f.write(append)\n",
        "            \n",
        "\n",
        "def find_mean_std(dataset):\n",
        "    assert dataset.ndim >= 2\n",
        "    print(dataset.shape)\n",
        "    \n",
        "    temp = dataset.reshape(dataset.shape[-1], -1)\n",
        "    \n",
        "    print(temp.shape)\n",
        "    \n",
        "    return np.array(temp.mean(axis=1)) / 255.0, np.array(temp.std(axis=1)) / 255.0\n",
        "\n",
        "\n",
        "def imshow(inp, title=None):\n",
        "    \"\"\"Imshow for Tensor.\"\"\"\n",
        "    inp = inp.numpy().transpose((1, 2, 0))\n",
        "    inp = np.clip(inp, 0, 1)\n",
        "    plt.imshow(inp)\n",
        "    if title is not None:\n",
        "        plt.title(title)\n",
        "        \n",
        "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
        "    \n",
        "def load_image(path, ):\n",
        "    img = Image.open(path).convert('L')\n",
        "    # img = Image.open(path)\n",
        "    img.load()\n",
        "    \n",
        "    return transforms.ToTensor()(img)\n",
        "\n",
        "# https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "IQcSupl5bp3r"
      },
      "outputs": [],
      "source": [
        "from os.path import exists\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import random_split, Dataset, DataLoader\n",
        "\n",
        "from torchvision.io import read_image, ImageReadMode\n",
        "from torchvision import transforms\n",
        "\n",
        "# id_dict = {}\n",
        "# for i, line in enumerate(open('data/wnids.txt', 'r')):\n",
        "#   id_dict[line.replace('\\n', '')] = i\n",
        "\n",
        "# Notes:\n",
        "# 1: Surprise\n",
        "# 2: Fear\n",
        "# 3: Disgust\n",
        "# 4: Happiness\n",
        "# 5: Sadness\n",
        "# 6: Anger\n",
        "# 7: Neutral\n",
        "\n",
        "# CLASS_LABELS = {\n",
        "#     '0': 'Surprise',\n",
        "#     '1': 'Fear',\n",
        "#     '2': 'Disgust',\n",
        "#     '3': 'Happiness',\n",
        "#     '4': 'Sadness',\n",
        "#     '5': 'Anger',\n",
        "#     '6': 'Neutral',\n",
        "# }\n",
        "\n",
        "CLASS_LABELS = {\n",
        "    '0': 'Angry',\n",
        "    '1': 'Disgust',\n",
        "    '2': 'Fear',\n",
        "    '3': 'Happy',\n",
        "    '4': 'Sad',\n",
        "    '5': 'Surprise',\n",
        "    '6': 'Neutral',\n",
        "}\n",
        "\n",
        "IMG_PATH = 'dataset/img/'\n",
        "# IMG_PATH = 'dataset/test/'\n",
        "INPUT_SIZE=48\n",
        "\n",
        "class CustomImageNetDataset(Dataset):\n",
        "    def __init__(self, transform=None, train=True):\n",
        "        self.img_path = IMG_PATH\n",
        "        # self.df = pd.read_csv('dataset/train.csv' if train else 'dataset/test.csv')\n",
        "        self.df = pd.read_csv('data/train.csv' if train else 'data/train.csv').sample(n=1000)\n",
        "\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df.index)\n",
        "\n",
        "    def get_targets(self):\n",
        "        return self.df['emotion']\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        obj = self.df.iloc[idx]\n",
        "        # image = load_image(self.img_path + obj['path'])\n",
        "        # label = obj['label']\n",
        "        \n",
        "        image = torch.Tensor(np.array(obj['pixels'].split(' '), dtype=np.uint8)).reshape(1, INPUT_SIZE, INPUT_SIZE)\n",
        "        label = obj['emotion']\n",
        "\n",
        "        # if image.shape[0] == 1:\n",
        "        #   image = read_image(self.img_path + obj['name'], ImageReadMode.GRAY)\n",
        "\n",
        "        if self.transform:\n",
        "          image = self.transform(image.type(torch.FloatTensor))\n",
        "\n",
        "        return image, label\n",
        "\n",
        "class CustomDataModule(pl.LightningDataModule):\n",
        "    def __init__(self, train_transforms = None, test_transforms = None, bs=32):\n",
        "        super().__init__()\n",
        "        self.bs = bs\n",
        "        \n",
        "        self.transform = train_transforms\n",
        "        \n",
        "        self.test_transform = test_transforms\n",
        "\n",
        "    def prepare_data(self):\n",
        "        pass\n",
        "\n",
        "    def __balance_val_split(self, dataset, val_split=0.):\n",
        "        targets = np.array(dataset.get_targets())\n",
        "        train_indices, val_indices = train_test_split(\n",
        "            np.arange(targets.shape[0]),\n",
        "            test_size=val_split,\n",
        "            stratify=targets\n",
        "        )\n",
        "        \n",
        "        train_dataset = Subset(dataset, indices=train_indices)\n",
        "        val_dataset = Subset(dataset, indices=val_indices)\n",
        "\n",
        "        return train_dataset, val_dataset\n",
        "\n",
        "    def setup(self, stage=None):\n",
        "        if stage == \"fit\" or stage is None:\n",
        "            train_ds_all = CustomImageNetDataset(transform=self.transform, train=True)\n",
        "            self.train_ds, self.val_ds = self.__balance_val_split(train_ds_all, val_split=0.05)\n",
        "\n",
        "        if stage == \"test\" or stage == \"predict\" or stage is None:\n",
        "            self.test_ds = CustomImageNetDataset(transform=self.test_transform, train=False)\n",
        "\n",
        "        return self\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        return DataLoader(self.train_ds, batch_size=self.bs, num_workers=12)\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        return DataLoader(self.val_ds, batch_size=self.bs, num_workers=12)\n",
        "\n",
        "    def test_dataloader(self):\n",
        "        return DataLoader(self.test_ds, batch_size=self.bs)\n",
        "\n",
        "    def predict_dataloader(self):\n",
        "        return DataLoader(self.test_ds, batch_size=self.bs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ngl3CuCw62kP",
        "outputId": "b31f45e0-e00a-4721-8771-a83340e54191"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 32, 46, 46]             320\n",
            "              ReLU-2           [-1, 32, 46, 46]               0\n",
            "            Conv2d-3           [-1, 64, 44, 44]          18,496\n",
            "              ReLU-4           [-1, 64, 44, 44]               0\n",
            "         MaxPool2d-5           [-1, 64, 14, 14]               0\n",
            "            Conv2d-6          [-1, 128, 12, 12]          73,856\n",
            "              ReLU-7          [-1, 128, 12, 12]               0\n",
            "         AvgPool2d-8            [-1, 128, 4, 4]               0\n",
            "           Flatten-9                 [-1, 2048]               0\n",
            "           Linear-10                  [-1, 128]         262,272\n",
            "             ReLU-11                  [-1, 128]               0\n",
            "          Dropout-12                  [-1, 128]               0\n",
            "           Linear-13                    [-1, 7]             903\n",
            "================================================================\n",
            "Total params: 355,847\n",
            "Trainable params: 355,847\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 3.34\n",
            "Params size (MB): 1.36\n",
            "Estimated Total Size (MB): 4.70\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# class FacialClassification(nn.Module):\n",
        "#     def __init__(self, in_channels=3):\n",
        "#         super().__init__()\n",
        "\n",
        "#         conv1_out_channels = 32\n",
        "#         self.conv1 = torch.nn.Conv2d(in_channels=in_channels, out_channels=conv1_out_channels, kernel_size=7, stride=2)\n",
        "#         self.relu = nn.ReLU(inplace=True)\n",
        "#         self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2)\n",
        "\n",
        "#         layer1_out_channels = 64\n",
        "#         self.layer1 = nn.Sequential(\n",
        "#             nn.Conv2d(in_channels=conv1_out_channels, out_channels=layer1_out_channels, kernel_size=3, bias=False),\n",
        "#             nn.ReLU(inplace=True),\n",
        "#             nn.Conv2d(in_channels=layer1_out_channels, out_channels=layer1_out_channels, kernel_size=3, bias=False),\n",
        "#             nn.BatchNorm2d(layer1_out_channels),\n",
        "#         )\n",
        "\n",
        "#         layer2_out_channels = 128\n",
        "#         self.layer2 = nn.Sequential(\n",
        "#             nn.Conv2d(in_channels=layer1_out_channels, out_channels=layer2_out_channels, kernel_size=3, bias=False),\n",
        "#             nn.ReLU(inplace=True),\n",
        "#             nn.Conv2d(in_channels=layer2_out_channels, out_channels=layer2_out_channels, kernel_size=3, bias=False),\n",
        "#             nn.BatchNorm2d(layer2_out_channels),\n",
        "#         )\n",
        "\n",
        "#         layer3_out_channels = 64\n",
        "#         self.layer3 = nn.Sequential(\n",
        "#             nn.Conv2d(in_channels=layer2_out_channels, out_channels=layer3_out_channels, kernel_size=3, bias=False),\n",
        "#             nn.ReLU(inplace=True),\n",
        "#             nn.Conv2d(in_channels=layer3_out_channels, out_channels=layer3_out_channels, kernel_size=3, bias=False),\n",
        "#             nn.BatchNorm2d(layer3_out_channels),\n",
        "#         )\n",
        "\n",
        "#         # self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "\n",
        "#         self.fc = nn.Sequential(\n",
        "#             nn.Flatten(),\n",
        "#             nn.Linear(in_features=layer3_out_channels, out_features=256),\n",
        "#             nn.ReLU(),\n",
        "#             nn.Linear(in_features=256, out_features=128),\n",
        "#             nn.Dropout(p=0.5),\n",
        "#             nn.Linear(in_features=128, out_features=len(CLASS_LABELS))\n",
        "#         )\n",
        "    \n",
        "#     def forward(self, x):\n",
        "#         # print(x.shape)\n",
        "        \n",
        "#         x = self.maxpool(self.relu(self.conv1(x)))\n",
        "#         x = self.layer1(x)\n",
        "#         x = self.layer2(x)\n",
        "#         x = self.layer3(x)\n",
        "#         x = self.fc(x)\n",
        "#         # x = self.fc(x)\n",
        "#         return x\n",
        "#         # return nn.functional.softmax(x, dim=1)\n",
        "\n",
        "class FacialClassification(nn.Module):\n",
        "    def __init__(self, in_channels=3):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv_layer = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=in_channels, out_channels=32, kernel_size=3),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3),\n",
        "            \n",
        "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.AvgPool2d(kernel_size=3),\n",
        "        )\n",
        "\n",
        "        # self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(in_features=2048, out_features=128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(p=0.1),\n",
        "            nn.Linear(in_features=128, out_features=len(CLASS_LABELS))\n",
        "        )\n",
        "    \n",
        "    def forward(self, x):\n",
        "        # print(x.shape)\n",
        "        x = self.conv_layer(x)\n",
        "\n",
        "        x = self.fc(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "summary(FacialClassification(1).to(\"cuda\"), (1, 48, 48))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "2PHvUN0Dbb39"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet101-63fe2227.pth\" to C:\\Users\\cseak/.cache\\torch\\hub\\checkpoints\\resnet101-63fe2227.pth\n",
            "100%|██████████| 171M/171M [01:46<00:00, 1.68MB/s] \n"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "'ResNet' object has no attribute 'features'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13940/1356551952.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m \u001b[0mFacialClassificationResNet18\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13940/1356551952.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[1;31m# freeze all VGG parameters since we're only optimizing the target image\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mparam\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_ft\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m             \u001b[0mparam\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequires_grad_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\cseak\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1175\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodules\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1176\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1177\u001b[1;33m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0m\u001b[0;32m   1178\u001b[0m             type(self).__name__, name))\n\u001b[0;32m   1179\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mAttributeError\u001b[0m: 'ResNet' object has no attribute 'features'"
          ]
        }
      ],
      "source": [
        "class FacialClassificationResNet18(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        # get the \"features\" portion of VGG19 (we will not need the \"classifier\" portion)\n",
        "        self.model_ft = torchvision.models.resnet101(pretrained=True)\n",
        "\n",
        "        # freeze all VGG parameters since we're only optimizing the target image\n",
        "        for param in self.model_ft.features.parameters():\n",
        "            param.requires_grad_(False)\n",
        "\n",
        "        num_ftrs = self.model_ft.fc.in_features\n",
        "        # Here the size of each output sample is set to 2.\n",
        "        # Alternatively, it can be generalized to nn.Linear(num_ftrs, len(class_names)).\n",
        "        self.model_ft.fc = nn.Linear(num_ftrs, len(CLASS_LABELS))\n",
        "\n",
        "    def forward(self, x):\n",
        "      out = self.model_ft(x)\n",
        "\n",
        "      return out\n",
        "  \n",
        "FacialClassificationResNet18()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "JBqk2Guo60nk"
      },
      "outputs": [],
      "source": [
        "class LitFacialClassification(pl.LightningModule):\n",
        "    def __init__(self, model):\n",
        "        super().__init__()\n",
        "        # self.save_hyperparameters()\n",
        "\n",
        "        self.model = model\n",
        "\n",
        "        self.criterion = nn.CrossEntropyLoss()\n",
        "        \n",
        "        self.lr = 0.0001\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        # training_step defines the train loop.\n",
        "        x, y = batch\n",
        "\n",
        "        y_hat = self.model(x)\n",
        "        # print(y_hat[0], y[0])\n",
        "\n",
        "        loss = self.criterion(y_hat, y)\n",
        "\n",
        "        preds = torch.argmax(y_hat, dim=1)\n",
        "        acc = accuracy(preds, y)\n",
        "\n",
        "        self.log('train_loss', loss, on_step=False, on_epoch=True, logger=True, prog_bar=True)\n",
        "        self.log('train_acc', acc, on_step=False, on_epoch=True, logger=True, prog_bar=True)\n",
        "\n",
        "        return {'loss': loss, 'progress_bar': {'train_acc': acc}}\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        result = self.training_step(batch, batch_idx)\n",
        "\n",
        "        return {'loss': result['loss'], 'progress_bar': {'val_acc': result['progress_bar']['train_acc']}}\n",
        "\n",
        "    def validation_epoch_end(self, val_outputs):\n",
        "        avg_val_loss = torch.tensor([x['loss'] for x in val_outputs]).mean()\n",
        "        avg_val_acc = torch.tensor([x['progress_bar']['val_acc'] for x in val_outputs]).mean()\n",
        "\n",
        "        return {'loss': avg_val_loss, 'progress_bar': {'val_acc': avg_val_acc}}\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        result = self.training_step(batch, batch_idx)\n",
        "\n",
        "        return {'loss': result['loss'], 'progress_bar': {'test_acc': result['progress_bar']['train_acc']}}\n",
        "\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = torch.optim.Adam(self.parameters(), lr=self.lr)\n",
        "\n",
        "        return optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "id": "rd_2XV5M_QNA",
        "outputId": "9affa24f-bce6-46ec-c8b8-c026138028d1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x1f561002dc0>"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\r\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n<svg height=\"263.63625pt\" version=\"1.1\" viewBox=\"0 0 251.565 263.63625\" width=\"251.565pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n <metadata>\r\n  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\r\n   <cc:Work>\r\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\r\n    <dc:date>2022-06-29T13:48:31.944259</dc:date>\r\n    <dc:format>image/svg+xml</dc:format>\r\n    <dc:creator>\r\n     <cc:Agent>\r\n      <dc:title>Matplotlib v3.4.3, https://matplotlib.org/</dc:title>\r\n     </cc:Agent>\r\n    </dc:creator>\r\n   </cc:Work>\r\n  </rdf:RDF>\r\n </metadata>\r\n <defs>\r\n  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\r\n </defs>\r\n <g id=\"figure_1\">\r\n  <g id=\"patch_1\">\r\n   <path d=\"M 0 263.63625 \r\nL 251.565 263.63625 \r\nL 251.565 0 \r\nL 0 0 \r\nz\r\n\"/>\r\n  </g>\r\n  <g id=\"axes_1\">\r\n   <g id=\"patch_2\">\r\n    <path d=\"M 26.925 239.758125 \r\nL 244.365 239.758125 \r\nL 244.365 22.318125 \r\nL 26.925 22.318125 \r\nz\r\n\"/>\r\n   </g>\r\n   <g clip-path=\"url(#pe978013d65)\">\r\n    <image height=\"218\" id=\"image42701294af\" transform=\"scale(1 -1)translate(0 -218)\" width=\"218\" x=\"26.925\" xlink:href=\"data:image/png;base64,\r\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\" y=\"-21.758125\"/>\r\n   </g>\r\n   <g id=\"matplotlib.axis_1\">\r\n    <g id=\"xtick_1\">\r\n     <g id=\"line2d_1\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL 0 3.5 \r\n\" id=\"m6990afb062\" style=\"stroke:#ffffff;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"fill:#ffffff;stroke:#ffffff;stroke-width:0.8;\" x=\"29.19\" xlink:href=\"#m6990afb062\" y=\"239.758125\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_1\">\r\n      <!-- 0 -->\r\n      <g style=\"fill:#ffffff;\" transform=\"translate(26.00875 254.356563)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 2034 4250 \r\nQ 1547 4250 1301 3770 \r\nQ 1056 3291 1056 2328 \r\nQ 1056 1369 1301 889 \r\nQ 1547 409 2034 409 \r\nQ 2525 409 2770 889 \r\nQ 3016 1369 3016 2328 \r\nQ 3016 3291 2770 3770 \r\nQ 2525 4250 2034 4250 \r\nz\r\nM 2034 4750 \r\nQ 2819 4750 3233 4129 \r\nQ 3647 3509 3647 2328 \r\nQ 3647 1150 3233 529 \r\nQ 2819 -91 2034 -91 \r\nQ 1250 -91 836 529 \r\nQ 422 1150 422 2328 \r\nQ 422 3509 836 4129 \r\nQ 1250 4750 2034 4750 \r\nz\r\n\" id=\"DejaVuSans-30\" transform=\"scale(0.015625)\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-30\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_2\">\r\n     <g id=\"line2d_2\">\r\n      <g>\r\n       <use style=\"fill:#ffffff;stroke:#ffffff;stroke-width:0.8;\" x=\"74.49\" xlink:href=\"#m6990afb062\" y=\"239.758125\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_2\">\r\n      <!-- 10 -->\r\n      <g style=\"fill:#ffffff;\" transform=\"translate(68.1275 254.356563)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 794 531 \r\nL 1825 531 \r\nL 1825 4091 \r\nL 703 3866 \r\nL 703 4441 \r\nL 1819 4666 \r\nL 2450 4666 \r\nL 2450 531 \r\nL 3481 531 \r\nL 3481 0 \r\nL 794 0 \r\nL 794 531 \r\nz\r\n\" id=\"DejaVuSans-31\" transform=\"scale(0.015625)\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-31\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_3\">\r\n     <g id=\"line2d_3\">\r\n      <g>\r\n       <use style=\"fill:#ffffff;stroke:#ffffff;stroke-width:0.8;\" x=\"119.79\" xlink:href=\"#m6990afb062\" y=\"239.758125\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_3\">\r\n      <!-- 20 -->\r\n      <g style=\"fill:#ffffff;\" transform=\"translate(113.4275 254.356563)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 1228 531 \r\nL 3431 531 \r\nL 3431 0 \r\nL 469 0 \r\nL 469 531 \r\nQ 828 903 1448 1529 \r\nQ 2069 2156 2228 2338 \r\nQ 2531 2678 2651 2914 \r\nQ 2772 3150 2772 3378 \r\nQ 2772 3750 2511 3984 \r\nQ 2250 4219 1831 4219 \r\nQ 1534 4219 1204 4116 \r\nQ 875 4013 500 3803 \r\nL 500 4441 \r\nQ 881 4594 1212 4672 \r\nQ 1544 4750 1819 4750 \r\nQ 2544 4750 2975 4387 \r\nQ 3406 4025 3406 3419 \r\nQ 3406 3131 3298 2873 \r\nQ 3191 2616 2906 2266 \r\nQ 2828 2175 2409 1742 \r\nQ 1991 1309 1228 531 \r\nz\r\n\" id=\"DejaVuSans-32\" transform=\"scale(0.015625)\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-32\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_4\">\r\n     <g id=\"line2d_4\">\r\n      <g>\r\n       <use style=\"fill:#ffffff;stroke:#ffffff;stroke-width:0.8;\" x=\"165.09\" xlink:href=\"#m6990afb062\" y=\"239.758125\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_4\">\r\n      <!-- 30 -->\r\n      <g style=\"fill:#ffffff;\" transform=\"translate(158.7275 254.356563)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 2597 2516 \r\nQ 3050 2419 3304 2112 \r\nQ 3559 1806 3559 1356 \r\nQ 3559 666 3084 287 \r\nQ 2609 -91 1734 -91 \r\nQ 1441 -91 1130 -33 \r\nQ 819 25 488 141 \r\nL 488 750 \r\nQ 750 597 1062 519 \r\nQ 1375 441 1716 441 \r\nQ 2309 441 2620 675 \r\nQ 2931 909 2931 1356 \r\nQ 2931 1769 2642 2001 \r\nQ 2353 2234 1838 2234 \r\nL 1294 2234 \r\nL 1294 2753 \r\nL 1863 2753 \r\nQ 2328 2753 2575 2939 \r\nQ 2822 3125 2822 3475 \r\nQ 2822 3834 2567 4026 \r\nQ 2313 4219 1838 4219 \r\nQ 1578 4219 1281 4162 \r\nQ 984 4106 628 3988 \r\nL 628 4550 \r\nQ 988 4650 1302 4700 \r\nQ 1616 4750 1894 4750 \r\nQ 2613 4750 3031 4423 \r\nQ 3450 4097 3450 3541 \r\nQ 3450 3153 3228 2886 \r\nQ 3006 2619 2597 2516 \r\nz\r\n\" id=\"DejaVuSans-33\" transform=\"scale(0.015625)\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-33\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_5\">\r\n     <g id=\"line2d_5\">\r\n      <g>\r\n       <use style=\"fill:#ffffff;stroke:#ffffff;stroke-width:0.8;\" x=\"210.39\" xlink:href=\"#m6990afb062\" y=\"239.758125\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_5\">\r\n      <!-- 40 -->\r\n      <g style=\"fill:#ffffff;\" transform=\"translate(204.0275 254.356563)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 2419 4116 \r\nL 825 1625 \r\nL 2419 1625 \r\nL 2419 4116 \r\nz\r\nM 2253 4666 \r\nL 3047 4666 \r\nL 3047 1625 \r\nL 3713 1625 \r\nL 3713 1100 \r\nL 3047 1100 \r\nL 3047 0 \r\nL 2419 0 \r\nL 2419 1100 \r\nL 313 1100 \r\nL 313 1709 \r\nL 2253 4666 \r\nz\r\n\" id=\"DejaVuSans-34\" transform=\"scale(0.015625)\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-34\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"matplotlib.axis_2\">\r\n    <g id=\"ytick_1\">\r\n     <g id=\"line2d_6\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL -3.5 0 \r\n\" id=\"mc4adb69ccf\" style=\"stroke:#ffffff;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"fill:#ffffff;stroke:#ffffff;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#mc4adb69ccf\" y=\"24.583125\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_6\">\r\n      <!-- 0 -->\r\n      <g style=\"fill:#ffffff;\" transform=\"translate(13.5625 28.382344)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-30\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_2\">\r\n     <g id=\"line2d_7\">\r\n      <g>\r\n       <use style=\"fill:#ffffff;stroke:#ffffff;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#mc4adb69ccf\" y=\"69.883125\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_7\">\r\n      <!-- 10 -->\r\n      <g style=\"fill:#ffffff;\" transform=\"translate(7.2 73.682344)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-31\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_3\">\r\n     <g id=\"line2d_8\">\r\n      <g>\r\n       <use style=\"fill:#ffffff;stroke:#ffffff;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#mc4adb69ccf\" y=\"115.183125\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_8\">\r\n      <!-- 20 -->\r\n      <g style=\"fill:#ffffff;\" transform=\"translate(7.2 118.982344)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-32\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_4\">\r\n     <g id=\"line2d_9\">\r\n      <g>\r\n       <use style=\"fill:#ffffff;stroke:#ffffff;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#mc4adb69ccf\" y=\"160.483125\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_9\">\r\n      <!-- 30 -->\r\n      <g style=\"fill:#ffffff;\" transform=\"translate(7.2 164.282344)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-33\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_5\">\r\n     <g id=\"line2d_10\">\r\n      <g>\r\n       <use style=\"fill:#ffffff;stroke:#ffffff;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#mc4adb69ccf\" y=\"205.783125\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_10\">\r\n      <!-- 40 -->\r\n      <g style=\"fill:#ffffff;\" transform=\"translate(7.2 209.582344)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-34\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"patch_3\">\r\n    <path d=\"M 26.925 239.758125 \r\nL 26.925 22.318125 \r\n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_4\">\r\n    <path d=\"M 244.365 239.758125 \r\nL 244.365 22.318125 \r\n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_5\">\r\n    <path d=\"M 26.925 239.758125 \r\nL 244.365 239.758125 \r\n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_6\">\r\n    <path d=\"M 26.925 22.318125 \r\nL 244.365 22.318125 \r\n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"text_11\">\r\n    <!-- Fear -->\r\n    <g style=\"fill:#ffffff;\" transform=\"translate(122.68875 16.318125)scale(0.12 -0.12)\">\r\n     <defs>\r\n      <path d=\"M 628 4666 \r\nL 3309 4666 \r\nL 3309 4134 \r\nL 1259 4134 \r\nL 1259 2759 \r\nL 3109 2759 \r\nL 3109 2228 \r\nL 1259 2228 \r\nL 1259 0 \r\nL 628 0 \r\nL 628 4666 \r\nz\r\n\" id=\"DejaVuSans-46\" transform=\"scale(0.015625)\"/>\r\n      <path d=\"M 3597 1894 \r\nL 3597 1613 \r\nL 953 1613 \r\nQ 991 1019 1311 708 \r\nQ 1631 397 2203 397 \r\nQ 2534 397 2845 478 \r\nQ 3156 559 3463 722 \r\nL 3463 178 \r\nQ 3153 47 2828 -22 \r\nQ 2503 -91 2169 -91 \r\nQ 1331 -91 842 396 \r\nQ 353 884 353 1716 \r\nQ 353 2575 817 3079 \r\nQ 1281 3584 2069 3584 \r\nQ 2775 3584 3186 3129 \r\nQ 3597 2675 3597 1894 \r\nz\r\nM 3022 2063 \r\nQ 3016 2534 2758 2815 \r\nQ 2500 3097 2075 3097 \r\nQ 1594 3097 1305 2825 \r\nQ 1016 2553 972 2059 \r\nL 3022 2063 \r\nz\r\n\" id=\"DejaVuSans-65\" transform=\"scale(0.015625)\"/>\r\n      <path d=\"M 2194 1759 \r\nQ 1497 1759 1228 1600 \r\nQ 959 1441 959 1056 \r\nQ 959 750 1161 570 \r\nQ 1363 391 1709 391 \r\nQ 2188 391 2477 730 \r\nQ 2766 1069 2766 1631 \r\nL 2766 1759 \r\nL 2194 1759 \r\nz\r\nM 3341 1997 \r\nL 3341 0 \r\nL 2766 0 \r\nL 2766 531 \r\nQ 2569 213 2275 61 \r\nQ 1981 -91 1556 -91 \r\nQ 1019 -91 701 211 \r\nQ 384 513 384 1019 \r\nQ 384 1609 779 1909 \r\nQ 1175 2209 1959 2209 \r\nL 2766 2209 \r\nL 2766 2266 \r\nQ 2766 2663 2505 2880 \r\nQ 2244 3097 1772 3097 \r\nQ 1472 3097 1187 3025 \r\nQ 903 2953 641 2809 \r\nL 641 3341 \r\nQ 956 3463 1253 3523 \r\nQ 1550 3584 1831 3584 \r\nQ 2591 3584 2966 3190 \r\nQ 3341 2797 3341 1997 \r\nz\r\n\" id=\"DejaVuSans-61\" transform=\"scale(0.015625)\"/>\r\n      <path d=\"M 2631 2963 \r\nQ 2534 3019 2420 3045 \r\nQ 2306 3072 2169 3072 \r\nQ 1681 3072 1420 2755 \r\nQ 1159 2438 1159 1844 \r\nL 1159 0 \r\nL 581 0 \r\nL 581 3500 \r\nL 1159 3500 \r\nL 1159 2956 \r\nQ 1341 3275 1631 3429 \r\nQ 1922 3584 2338 3584 \r\nQ 2397 3584 2469 3576 \r\nQ 2541 3569 2628 3553 \r\nL 2631 2963 \r\nz\r\n\" id=\"DejaVuSans-72\" transform=\"scale(0.015625)\"/>\r\n     </defs>\r\n     <use xlink:href=\"#DejaVuSans-46\"/>\r\n     <use x=\"52.019531\" xlink:href=\"#DejaVuSans-65\"/>\r\n     <use x=\"113.542969\" xlink:href=\"#DejaVuSans-61\"/>\r\n     <use x=\"174.822266\" xlink:href=\"#DejaVuSans-72\"/>\r\n    </g>\r\n   </g>\r\n  </g>\r\n </g>\r\n <defs>\r\n  <clipPath id=\"pe978013d65\">\r\n   <rect height=\"217.44\" width=\"217.44\" x=\"26.925\" y=\"22.318125\"/>\r\n  </clipPath>\r\n </defs>\r\n</svg>\r\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "img, label = next(iter(CustomDataModule().setup(\"fit\").train_dataloader().dataset))\n",
        "# one_img = btx[0][0]\n",
        "# one_label = btx[1][0]\n",
        "# one_img.shape\n",
        "# imshow(img)\n",
        "\n",
        "# plt.title(CLASS_LABELS[str(label)])\n",
        "# img =img.numpy()\n",
        "# if img.shape[0] == 3:\n",
        "#   img = img.transpose((1, 2, 0))\n",
        "# plt.imshow(img.squeeze(), cmap='gray' if img.shape[0] == 1 else None)\n",
        "\n",
        "plt.title(CLASS_LABELS[str(label)])\n",
        "plt.imshow(img.numpy().reshape(48, 48, 1), cmap='gray')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "EPOCHS = 5\n",
        "BATCH_SIZE = 32\n",
        "# Loss and optimizer\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "def train(model, learning_rate, train_dl, val_dl, epochs):\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "    \n",
        "    total_step = len(train_dl)\n",
        "    for epoch in range(epochs):\n",
        "        losses = []\n",
        "        model.train()\n",
        "        for images, labels in iter(train_dl):\n",
        "            images = images.to(DEVICE)\n",
        "            labels = labels.to(DEVICE)\n",
        "            # print(images.shape, labels.shape)\n",
        "            # Forward pass\n",
        "            outputs = model(images)\n",
        "            # print(outputs.shape)\n",
        "            loss = criterion(outputs, labels)\n",
        "            \n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "            losses.append(loss.item())\n",
        "            \n",
        "        val_loss, val_acc = evaluate(model, val_dl, True)\n",
        "            \n",
        "        print ('Epoch [{}/{}], Training Loss: {:.4f}' \n",
        "                      .format(epoch+1, epochs, sum(losses) / len(losses)))\n",
        "        print ('Epoch [{}/{}], Validation Loss: {:.4f}, Validation Accuracy: {:.4f}' \n",
        "                      .format(epoch+1, epochs, val_loss, val_acc))\n",
        "      \n",
        "def evaluate(model, val_dl, run_once=False):\n",
        "    row = 10\n",
        "    col = 6\n",
        "    i = 1\n",
        "    plt.figure(figsize=(25, 20))\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        rtn_preds = []\n",
        "        rtn_labels = []\n",
        "        rtn_losses = []\n",
        "        for images, labels in val_dl:\n",
        "            images = images.to(DEVICE)\n",
        "            labels = labels.to(DEVICE)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            \n",
        "            # print(outputs[0])\n",
        "            predicted = torch.argmax(outputs, dim=1).long()\n",
        "            # print(predicted)\n",
        "            total += labels.shape[0]\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "            rtn_preds.extend(predicted.detach().cpu().numpy())\n",
        "            rtn_labels.extend(labels.detach().cpu().numpy())\n",
        "            rtn_losses.append(loss.detach().cpu().item())\n",
        "            \n",
        "            # print(labels.shape)\n",
        "            # print(\"Correct: \", labels.detach().cpu().numpy()[predicted.detach().cpu().numpy() != labels.detach().cpu().numpy()])\n",
        "            # print(\"Incorrect: \", predicted.detach().cpu().numpy()[predicted.detach().cpu().numpy() != labels.detach().cpu().numpy()])\n",
        "            # print(labels)\n",
        "            # print(predicted)\n",
        "            # print(predicted.detach().cpu().numpy()[predicted.detach().cpu().numpy() != labels.detach().cpu().numpy()])\n",
        "            for ind, incorrect in enumerate(predicted):\n",
        "                if predicted[ind] == labels[ind]:\n",
        "                    continue\n",
        "                \n",
        "                subplot = plt.subplot(row, col, i, label=incorrect)\n",
        "                subplot.imshow(images[ind].detach().cpu().numpy().squeeze(), cmap='gray')\n",
        "                subplot.axis('off')\n",
        "                subplot.set_title(\"Ind: \" + str(ind) + \" P: \" + CLASS_LABELS[str(incorrect.item())] + \", A: \" + CLASS_LABELS[str(labels[ind].cpu().item())])\n",
        "                i += 1\n",
        "            \n",
        "            if run_once:\n",
        "                break\n",
        "\n",
        "        print('Accuracy of the network on the', total ,'validation images: {} %'.format(100 * correct / total))\n",
        "\n",
        "    return np.array(rtn_losses).mean(), 100 * correct / total\n",
        "\n",
        "def test(model, test_dl):\n",
        "    fig = plt.figure(figsize=(25, 20))\n",
        "\n",
        "    col = 8\n",
        "    row = BATCH_SIZE/col\n",
        "    rtn = {\n",
        "        'id': [],\n",
        "        'has_cactus': []\n",
        "    }\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        for idx, (images, labels, img_names) in enumerate(test_dl):\n",
        "            images = images.to(DEVICE)\n",
        "            labels = labels.to(DEVICE)\n",
        "            outputs = model(images)\n",
        "            # print(outputs[0])\n",
        "            predicted = (outputs.reshape(-1) > 0.5).long()\n",
        "            rtn['has_cactus'].extend(outputs.reshape(-1).detach().cpu().numpy())\n",
        "            rtn['id'].extend(img_names)\n",
        "\n",
        "            if idx % 10 == 0:\n",
        "              for i, name in enumerate(img_names):\n",
        "                subplot = plt.subplot(row, col, i + 1, label=name)\n",
        "                subplot.imshow(read_image('test/' + name).reshape(3, 32, 32).T.numpy())\n",
        "                subplot.axis('off')\n",
        "                subplot.set_title(predicted[i])\n",
        "\n",
        "    return rtn\n",
        "\n",
        "def show_confusion_matrix(model, y_true, y_preds):\n",
        "    print(\"Confusion Matrix of\", type(model).__name__)\n",
        "    mat = confusion_matrix(y_true, y_preds)\n",
        "    sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False)\n",
        "    plt.xlabel('true label')\n",
        "    plt.ylabel('predicted label')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 327,
          "referenced_widgets": [
            "76a29a2444f24315864aeda040b653fe",
            "0842aafc1f9d4cf4bbf20cba117217e0",
            "14492847902143c097725bf465fbb815",
            "7ef89c79720f4631988e416021092ca1",
            "448789856cf046e6af46922737d85347",
            "1557bf48e4d249b1a4ecb6431ec5d6c3",
            "320d78eb882b4c24a817fcf32f3cf879",
            "987334a6e9d24d088d10dd1611fddc55",
            "a8f79e1e5c344ee8831812a388256e40",
            "1881f4ef3f1641ae9135df0b6cc3dd20",
            "fa31d6529bd54739a1cc1584853227f2",
            "922f0488b3ff4c16a76319cdd9ef9bc0",
            "e189a18b60434a7c90b9c411dcc3fb48",
            "4c9c95a8ee3949eaa55e451bacebe0df",
            "d26a93f1f286432baedce846789aad66",
            "a8e7551243d14e9ba6a4553ac7bd98a6",
            "4d70108e3d2248eb9cf863a76c5e713f",
            "3c2a86250e29410d904202fb8411c6b5",
            "53b47c9f4de64404b1422f9a88869e5c",
            "cd937a4fc493428abbb4accbeb883fd5",
            "2707b8d3635f4469815e347c561955a9",
            "7d4af37e834b4ebb968e23d4147ad117"
          ]
        },
        "id": "8m2kvsWg1HXT",
        "outputId": "44d948ac-444b-4c12-881d-2d4472741ffb"
      },
      "outputs": [],
      "source": [
        "# 15 339 total images in label.txt\n",
        "\n",
        "facial_model = FacialClassification(in_channels=1)\n",
        "data_module = CustomDataModule(\n",
        "    train_transforms=transforms.Compose([\n",
        "            transforms.ToPILImage(),\n",
        "            # transforms.RandomHorizontalFlip(0.5),\n",
        "            # transforms.RandomRotation(degrees=(-90, 90)),\n",
        "            # transforms.RandomVerticalFlip(0.5),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(0.5, 0.5)]),\n",
        "    test_transforms=transforms.Compose([\n",
        "            transforms.ToPILImage(),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(0.5, 0.5)]),\n",
        ")\n",
        "\n",
        "data_module.setup(\"fit\")\n",
        "\n",
        "# train_dl = data_module.train_dataloader()\n",
        "# val_dl = data_module.val_dataloader()\n",
        "# test_dl = data_module.test_dataloader()\n",
        "\n",
        "# train model\n",
        "# trainer = pl.Trainer(accelerator='gpu' if DEVICE == 'cuda' else 'cpu', max_epochs=EPOCHS, auto_select_gpus=True, log_every_n_steps=10)\n",
        "# trainer = pl.Trainer(accelerator='cpu', max_epochs=EPOCHS, auto_select_gpus=True, log_every_n_steps=10)\n",
        "# trainer.fit(facial_model, datamodule=data_module)\n",
        "# trainer.test(model=facial_model, datamodule=data_module)\n",
        "# trainer.save_checkpoint(\"save.ckpt\")  \n",
        "\n",
        "train(facial_model.to(DEVICE), learning_rate=0.001, epochs=EPOCHS, train_dl=data_module.train_dataloader(), val_dl=data_module.val_dataloader())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E7yVFEXX2tqQ"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "C:\\Users\\cseak\\anaconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:240: PossibleUserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
            "  rank_zero_warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing DataLoader 0: 100%|██████████| 96/96 [00:06<00:00, 15.21it/s]\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "       Test metric             DataLoader 0\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "        train_acc           0.38624510169029236\n",
            "       train_loss           1.6327896118164062\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[{'train_loss': 1.6327896118164062, 'train_acc': 0.38624510169029236}]"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer.test(model=facial_model, datamodule=data_module)\n",
        "# trainer.test(ckpt_path='save.ckpt', datamodule=data_module)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Facial_emotional_detector_v1.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.9.7 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "vscode": {
      "interpreter": {
        "hash": "b2bb06df3a58841ba0c26b5f09bf2e9d1ef6be6ba3138ea8c8abfadc118ea9ba"
      }
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0842aafc1f9d4cf4bbf20cba117217e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1557bf48e4d249b1a4ecb6431ec5d6c3",
            "placeholder": "​",
            "style": "IPY_MODEL_320d78eb882b4c24a817fcf32f3cf879",
            "value": "Sanity Checking DataLoader 0: 100%"
          }
        },
        "14492847902143c097725bf465fbb815": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_987334a6e9d24d088d10dd1611fddc55",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a8f79e1e5c344ee8831812a388256e40",
            "value": 2
          }
        },
        "1557bf48e4d249b1a4ecb6431ec5d6c3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1881f4ef3f1641ae9135df0b6cc3dd20": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2707b8d3635f4469815e347c561955a9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "320d78eb882b4c24a817fcf32f3cf879": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3c2a86250e29410d904202fb8411c6b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "448789856cf046e6af46922737d85347": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "4c9c95a8ee3949eaa55e451bacebe0df": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_53b47c9f4de64404b1422f9a88869e5c",
            "max": 385,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cd937a4fc493428abbb4accbeb883fd5",
            "value": 0
          }
        },
        "4d70108e3d2248eb9cf863a76c5e713f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "53b47c9f4de64404b1422f9a88869e5c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "76a29a2444f24315864aeda040b653fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0842aafc1f9d4cf4bbf20cba117217e0",
              "IPY_MODEL_14492847902143c097725bf465fbb815",
              "IPY_MODEL_7ef89c79720f4631988e416021092ca1"
            ],
            "layout": "IPY_MODEL_448789856cf046e6af46922737d85347"
          }
        },
        "7d4af37e834b4ebb968e23d4147ad117": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7ef89c79720f4631988e416021092ca1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1881f4ef3f1641ae9135df0b6cc3dd20",
            "placeholder": "​",
            "style": "IPY_MODEL_fa31d6529bd54739a1cc1584853227f2",
            "value": " 2/2 [00:26&lt;00:00, 13.19s/it]"
          }
        },
        "922f0488b3ff4c16a76319cdd9ef9bc0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e189a18b60434a7c90b9c411dcc3fb48",
              "IPY_MODEL_4c9c95a8ee3949eaa55e451bacebe0df",
              "IPY_MODEL_d26a93f1f286432baedce846789aad66"
            ],
            "layout": "IPY_MODEL_a8e7551243d14e9ba6a4553ac7bd98a6"
          }
        },
        "987334a6e9d24d088d10dd1611fddc55": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a8e7551243d14e9ba6a4553ac7bd98a6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "a8f79e1e5c344ee8831812a388256e40": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cd937a4fc493428abbb4accbeb883fd5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d26a93f1f286432baedce846789aad66": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2707b8d3635f4469815e347c561955a9",
            "placeholder": "​",
            "style": "IPY_MODEL_7d4af37e834b4ebb968e23d4147ad117",
            "value": " 0/385 [00:00&lt;?, ?it/s]"
          }
        },
        "e189a18b60434a7c90b9c411dcc3fb48": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4d70108e3d2248eb9cf863a76c5e713f",
            "placeholder": "​",
            "style": "IPY_MODEL_3c2a86250e29410d904202fb8411c6b5",
            "value": "Epoch 0:   0%"
          }
        },
        "fa31d6529bd54739a1cc1584853227f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
